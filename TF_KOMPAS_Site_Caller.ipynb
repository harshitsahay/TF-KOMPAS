{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-KOMPAS: Site caller\n",
    "\n",
    "Updated 11/25/19\n",
    "\n",
    "Author: Zachery Mielko\n",
    "\n",
    "Optimization and review: Tiffany Ho\n",
    "\n",
    "Review and feedback: Farica Zhuang\n",
    "\n",
    "The script requires the following dependencies:\n",
    "\n",
    "* pandas\n",
    "* numpy\n",
    "* biopython\n",
    "* pybedtools\n",
    "\n",
    "The script gives the following as **output**:\n",
    "- Bed file of centered sites (Centered_KOMPAS.bed)\n",
    "    - The Bed file is 0 based and of the format start inclusive, end exclusive. So half-open.\n",
    "    - Columns: Chromosome, Start, End, Orientation, Threshold Score\n",
    "- log file (optional)\n",
    "- Diagnostic tsv file showing calls and which kpositions matched to which genomic coordinates (optional)\n",
    "\n",
    "By default, the center position will be the midpoint of the core (rounded down), but it can be specifically chosen as an optional parameter.\n",
    "\n",
    "\n",
    "**Threshold Score**\n",
    "\n",
    "This is the threshold for when the site would be called. \n",
    "\n",
    "If k > core length (if multiple kmers exist that can fully describe the core), then the second score from **maximum** for those kmers is used. This is due to the requirnment of 2 overlapping kmers.\n",
    "\n",
    "If k <= core length (if multiple (or 1) kmers are needed to describe the core fully), then the **minimum** score for those kmers is used because only when threshold is set to that minimum or below would the site be called\n",
    "\n",
    "**Handles both palindromes and non-palindromes.**\n",
    "\n",
    "If the query is for a palindrome, there is an option isPalindome to set to True. All it does is remove - strand calls, since any match on one strand is a match on another. If this is set to false for a palindrome, it should give + and - matches representing both centered positions, or 2 calls per binding site.\n",
    "\n",
    "-------\n",
    "Latest update (11/25/19)\n",
    "* Diagnostic tsv file shows all searched peaks, even if no calls were made\n",
    "* Threshold score is now set up so you can use it as a substitute for running at different thresholds. Represents practical threshold given 2 overlapping, not theoretical. \n",
    "\n",
    "\n",
    "Update (11/20/19):\n",
    "* Fixed bug in coordinates for 0 vs 1 based. KOMPAS is now fully in-sync with half-open, 0 based formats used by bedtools, MACS, and UCSC (backend)\n",
    "\n",
    "\n",
    "--------\n",
    "To-do\n",
    "\n",
    "1. Vectorize site calling\n",
    "2. Introduce matrix output file of all called data as optional additional file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "################## Parameters ###############\n",
    "# Files and folders\n",
    "wkdir = \"/Users/ZMielko/Desktop/Test_KOMPAS/\"\n",
    "peakFile = '/Users/ZMielko/Desktop/Test_KOMPAS/ets1_k562_ENCSR000BKQ_idr.txt'\n",
    "genomeFile = '/Users/ZMielko/Desktop/In_Vivo_Project/Data/human_g1k_v37.fasta'\n",
    "kmerFile = '/Users/ZMielko/Desktop/Test_KOMPAS/aligned_ets1_8mer.txt'\n",
    "# kPosition of the core and where to center the call\n",
    "# core is right exclusionary, left inclusive [)\n",
    "core = (10,16) \n",
    "threshold = 0.3\n",
    "isPalindrome = False\n",
    "# Optional settings\n",
    "saveDiagnostic = True # saves table with calling information for each seq\n",
    "logFile = True\n",
    "centerPos = 12\n",
    "\n",
    "#############################################\n",
    "if centerPos == 'default':\n",
    "    centerPos = int((core[0] + core[1])/2)\n",
    "##### Imports ####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import reverse_complement\n",
    "import os\n",
    "from itertools import groupby \n",
    "from operator import itemgetter\n",
    "from pybedtools import BedTool\n",
    "\n",
    "#### Functions ####\n",
    "def readFasta(file):\n",
    "    '''\n",
    "    Reads a fasta file and turns it into a dataframe with forward and rc sequences\n",
    "    '''\n",
    "    entry = []\n",
    "    with open(file, \"r\") as input_handle:\n",
    "        for record in SeqIO.parse(input_handle, \"fasta\"):\n",
    "            entry.append([record.id, str(record.seq).upper(), len(record.seq), str(reverse_complement(record.seq)).upper()])\n",
    "    arr = np.array(entry)\n",
    "    df = pd.DataFrame({'seq_id':arr[:, 0], 'fwd':arr[:,1], 'seq_len':arr[:,2], 'rev_comp':arr[:,3]})\n",
    "    return df\n",
    "\n",
    "def checkConsecutive(l): \n",
    "        return sorted(l) == l \n",
    "\n",
    "def group_by_tuple(a, b):\n",
    "    '''\n",
    "    a = [(1,2), (3,), (4, 5, 6)]\n",
    "    b = [True, True, False, True, False, True]\n",
    "    output = [(True, True), (False,), (True, False, True)]\n",
    "    '''\n",
    "    prev_tup_head, curr_tup_head = 0, 0\n",
    "    grouped_b = []\n",
    "    for tup in a:\n",
    "        curr_tup_head = prev_tup_head+len(tup)\n",
    "        boo = tuple(b[prev_tup_head:curr_tup_head])\n",
    "        grouped_b.append(boo)\n",
    "        prev_tup_head = curr_tup_head\n",
    "    return grouped_b\n",
    "\n",
    "def call_sites(match_pos, kPosition,kScore, k, coreLen, ReqKpos, orient,seqLen, ScoredKpos):\n",
    "    '''\n",
    "    Given matches and their kpositions within a site, returns called sites and their score\n",
    "    '''\n",
    "    groupedMpos, calledMpos, calledKpos, calledKCenter, calledKScore = [], [], [], [], []\n",
    "    # get runs of consecutive numbers using groupby \n",
    "    for f, g in groupby(enumerate(match_pos), lambda x: x[1] - x[0]):\n",
    "        groupedMpos.append(tuple(map(itemgetter(1), g)))\n",
    "    groupedKpos = group_by_tuple(groupedMpos, kPosition)\n",
    "    groupedKscore = group_by_tuple(groupedMpos, kScore)\n",
    "    # If k is greater than core length\n",
    "    if k > coreLen:\n",
    "        for mpos_tuple, kpos_tuple, kscore_tuple in zip(groupedMpos, groupedKpos, groupedKscore):\n",
    "            if len(mpos_tuple) >= 2 and checkConsecutive(list(kpos_tuple)) and len(ReqKpos & set(kpos_tuple)) > 0:\n",
    "                # append tuple information for match position, kposition, center position\n",
    "                calledMpos.append(mpos_tuple)\n",
    "                calledKpos.append(kpos_tuple)\n",
    "                centerk = (centerPos - kpos_tuple[0]) + mpos_tuple[0]\n",
    "                calledKCenter.append(centerk)\n",
    "                # Scoring, find all ReqKpos and their associated scores, get the max score\n",
    "                site_score = []\n",
    "                for kpos, score in zip(kpos_tuple, kscore_tuple):\n",
    "                    if kpos in ScoredKpos:\n",
    "                        site_score.append(score)\n",
    "                site_score = sorted(site_score, reverse = True)[1] # Get the second highest score\n",
    "                calledKScore.append(site_score)\n",
    "    # if k is less than core length\n",
    "    else:\n",
    "        for mpos_tuple, kpos_tuple in zip(groupedMpos, groupedKpos, groupedKscore):\n",
    "            if checkConsecutive(list(kpos_tuple)) and len(ReqKpos & set(kpos_tuple)) == len(ReqKpos):\n",
    "                calledMpos.append(mpos_tuple)\n",
    "                calledKpos.append(kpos_tuple)\n",
    "                centerk = (centerPos - kpos_tuple[0]) + mpos_tuple[0] \n",
    "                calledKCenter.append(centerk)\n",
    "                # Scoring, find all ReqKpos and their associated scores, get the min score\n",
    "                site_score = 0.5 # maximum score\n",
    "                for kpos, score in zip(kpos_tuple, kscore_tuple):\n",
    "                    if kpos in ReqKpos and score < site_score:\n",
    "                        site_score = score\n",
    "                calledKScore.append(site_score)\n",
    "    if len(calledKCenter) == 0:\n",
    "        return([None,None,None, None])\n",
    "    elif orient == 'fwd':\n",
    "        return([calledKCenter,calledKScore, calledMpos, calledKpos])\n",
    "    else:\n",
    "        calledKCenter = list(map(lambda x: (seqLen - x) -1, calledKCenter)) \n",
    "        return([calledKCenter,calledKScore, calledMpos, calledKpos])\n",
    "        \n",
    "def parseID(df):\n",
    "    \"\"\"parseID takes the concatinated names given in fasta outputs from bedtool's getfasta \n",
    "    and turns them into bed compatible columns\"\"\"\n",
    "    chrom, start, end = [], [], []\n",
    "    for i in df.seq_id:\n",
    "        cr = i.split(':')\n",
    "        pos = cr[1].split('-')\n",
    "        chrom.append(cr[0])\n",
    "        start.append(int(pos[0]))\n",
    "        end.append(int(pos[1]))\n",
    "    df['Chromosome'] = chrom\n",
    "    df['Start'] = start\n",
    "    df['End'] = end\n",
    "    return(df)\n",
    "\n",
    "def convertToBed(df):\n",
    "    chrom, start, orient,scores = [],[],[],[]\n",
    "    for row in zip(df['Chromosome'],df['Start'],df['centerPlus'],df['scorePlus'],df['centerMinus'],df['scoreMinus']):\n",
    "        if row[2]:\n",
    "            for centerP, score in zip(row[2], row[3]): # + sites\n",
    "                chrom.append(row[0])\n",
    "                start.append(row[1] + centerP)\n",
    "                orient.append('+')\n",
    "                scores.append(score)\n",
    "        if row[4]:\n",
    "            for centerN, score in zip(row[4],row[5]): # - sites\n",
    "                chrom.append(row[0])\n",
    "                start.append(row[1] + centerN)\n",
    "                orient.append('-')\n",
    "                scores.append(score)\n",
    "    bedDF = pd.DataFrame({'chrom':chrom,'start':start, 'end':start,'orient':orient, 'score':scores})\n",
    "    bedDF['end'] = bedDF['end'] + 1 # exclusive end position\n",
    "    bedDF = bedDF.drop_duplicates().sort_values(by=['chrom','start']) # some sites overlap, will call the same centers\n",
    "    return(bedDF)\n",
    "##### Read in kmer data and process ####\n",
    "kmer = pd.read_csv(kmerFile, sep = '\\t')\n",
    "k = len(kmer['kmer'][0])\n",
    "coreLen = core[1] - core[0]\n",
    "# Find the kPositions required, any would be sufficient to call\n",
    "if k > coreLen: \n",
    "    searchEnd = core[1]\n",
    "    checkK = 0\n",
    "    ReqKpos = set() #\n",
    "    while checkK != core[0]:\n",
    "        checkK = searchEnd - k\n",
    "        if checkK <= core[0]:\n",
    "            ReqKpos.add(checkK)\n",
    "            searchEnd = searchEnd + 1\n",
    "# Or find the group of all kPositions that are needed, all or none\n",
    "else:\n",
    "    searchStart = core[0]\n",
    "    checkK = 0\n",
    "    ReqKpos = set()\n",
    "    while searchStart + k <= core[1]:\n",
    "        ReqKpos.add(searchStart)\n",
    "        searchStart = searchStart + 1\n",
    "# Determine flanks of ReqKPos for threshold score reporting\n",
    "ScoredKpos = ReqKpos.copy()\n",
    "ScoredKpos.add(min(ReqKpos) - 1)\n",
    "ScoredKpos.add(max(ReqKpos) + 1)        \n",
    "        \n",
    "\n",
    "kmerSearch = set(kmer[(kmer['Escore'] > threshold) & (kmer['kposition'].isin(ScoredKpos))]['kmer'])\n",
    "kDict = dict(zip(kmer['kmer'],kmer['kposition']))\n",
    "kScore = dict(zip(kmer['kmer'],kmer['Escore']))\n",
    "\n",
    "##### Generate a fasta file from peakFile ####\n",
    "peaks = pd.read_csv(peakFile, sep = '\\t',header = None, usecols=[0,1,2])\n",
    "# find out how long the peaks need to be to use them\n",
    "if coreLen > k:\n",
    "    minLen = coreLen\n",
    "else:\n",
    "    minLen = k + 1\n",
    "peaks = peaks[peaks[2]-peaks[1] > (minLen)].drop_duplicates() # filter for short sequences the caller would have trouble with\n",
    "peakBed = BedTool.from_dataframe(peaks)\n",
    "peakSequence = peakBed.sequence(fi = genomeFile)\n",
    "peakDF = readFasta(peakSequence.seqfn)\n",
    "peakDF = parseID(peakDF)\n",
    "del peakDF['seq_id']\n",
    "peakDF[['seq_len', 'Start','End']] = peakDF[['seq_len', 'Start','End']].astype(int) \n",
    "\n",
    "def kmerMatch(seq,seqLen,orient, k, kmerSearch,kDict, coreLen, ReqKpos):\n",
    "    \"\"\"\n",
    "    Returns matched positions in the sequence and their kpositions\n",
    "    \"\"\"\n",
    "    pos, kpos,kscore = [], [], []\n",
    "    for i in range(len(seq) - k + 1):\n",
    "        window = seq[i:i+k]\n",
    "        if window in kmerSearch:\n",
    "            pos.append(i)\n",
    "            kpos.append(kDict[window])\n",
    "            kscore.append(kScore[window])\n",
    "    if len(pos) <= 1: # must be at least 2 matches in the whole sequence, acts as a pre-filter\n",
    "        return(pd.Series([None,None,None, None]))\n",
    "    else:\n",
    "        return(pd.Series(call_sites(pos,kpos,kscore,k, coreLen, ReqKpos, orient, seqLen,ScoredKpos))) \n",
    "\n",
    "# Run kmerMatch on the peaks\n",
    "peakDF[[\"centerPlus\",\"scorePlus\",\"matchPlus\",\"kpositionPlus\"]] = peakDF.apply(lambda peakDF: kmerMatch(peakDF[\"fwd\"],peakDF[\"seq_len\"], 'fwd', k, kmerSearch, kDict, coreLen,ReqKpos), axis = 1) # search the forward strand\n",
    "peakDF[[\"centerMinus\",\"scoreMinus\",\"matchMinus\",\"kpositionMinus\"]] = peakDF.apply(lambda peakDF: kmerMatch(peakDF[\"rev_comp\"], peakDF[\"seq_len\"], 'rc', k, kmerSearch, kDict,coreLen,ReqKpos), axis = 1) # search the reverse complement\n",
    "if saveDiagnostic == True:\n",
    "    peakDF[['Chromosome','Start','End','centerPlus','scorePlus','matchPlus','kpositionPlus','centerMinus','scoreMinus','matchMinus','kpositionMinus']].to_csv(f\"{wkdir}Diagnostic_{threshold}_KOMPAS.tsv\", sep = '\\t')\n",
    "\n",
    "peakDF = peakDF[~peakDF['centerPlus'].isna() | ~peakDF['centerMinus'].isna()]\n",
    "finalBed = convertToBed(peakDF)\n",
    "if isPalindrome == True:\n",
    "    finalBed = finalBed.query(\"orient == '+'\")\n",
    "finalBed.to_csv(f'{wkdir}Centered_{threshold}_KOMPAS.bed', sep = '\\t', header = None, index = False)\n",
    "\n",
    "\n",
    "\n",
    "if logFile == True:\n",
    "    ##################\n",
    "    # Log the output #\n",
    "    ##################\n",
    "    f = open(wkdir + \"/KOMPASLog.txt\", \"a\")\n",
    "    f.write(\"##### Parameters ##### \\n\")\n",
    "    f.write(f\"Peak file: {peakFile}\"+ \"\\n\")\n",
    "    f.write(f\"Genome file: {genomeFile}\"+ \"\\n\")\n",
    "    f.write(f\"kmer file: {kmerFile}\"+ \"\\n\")\n",
    "    f.write(f\"Core kPositions: {core}\"+ \"\\n\")\n",
    "    f.write(f\"Center kPositions: {centerPos}\"+ \"\\n\")\n",
    "    f.write(f\"Threshold: {threshold}\"+ \"\\n\")\n",
    "    f.write(\"#Summary# \\n\")\n",
    "    f.write(f\"Final # of called sequences: {len(finalBed)}\"+ \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
